{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[空气质量指数(http://www.tianqihoubao.com/aqi/)](http://www.tianqihoubao.com/aqi/)  \n",
    "\n",
    "HTML基础  \n",
    "超链接 `<a href='链接地址'>链接的文字</a>`  \n",
    "在网页使用F12(或右键审查元素)可以调开控制台，查看网页源代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "爬虫项目整体代码：  \n",
    "[高民权_中国城市空气质量数据抓取_Github](https://github.com/fortyMiles/ChineseAirConditionCrawler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**处理城市编码**  \n",
    "将`<div class=\"citychk\">`copy下来，进一步处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\".join(open('./citychk.txt').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371 367\n",
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "m = re.findall('href=\"/aqi/\\w*.html\">.{0,5} ', html)\n",
    "\n",
    "# lambd = lambda x: (x.split('>')[1].strip(), x[11:x.index('.')])\n",
    "# or use function\n",
    "def generate_code(x):\n",
    "    end = x.index('.')\n",
    "    code = x[11:end]\n",
    "    name = x.split('>')[1].strip()\n",
    "    return name,code\n",
    "    \n",
    "city_coding = list(map(generate_code, m))\n",
    "\n",
    "# remove duplicate data\n",
    "print(len(city_coding), len(set(city_coding)))\n",
    "city_coding = set(city_coding)\n",
    "\n",
    "# save\n",
    "with open('./city_coding.txt', 'w') as f:\n",
    "    for line in city_coding:\n",
    "        f.write('\\t'.join(line) + '\\n')\n",
    "print('Saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github中的`get_location_info.py`文件对应city_coding的生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抓取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**首先安装包**  \n",
    "\n",
    "``` bash\n",
    "pip install bs4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取city_coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_coding(file='./city_coding'):\n",
    "    city_coding = {}\n",
    "    with open(file) as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            try: \n",
    "                city, coding = line.split('\\t')\n",
    "                city_coding[city.strip()] = coding.strip()\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    return city_coding\n",
    "\n",
    "city_coding = get_city_coding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拼接成自己想要的URL地址  \n",
    "\n",
    "如果是当前月份可以看到直接使用城市名称即可，如 http://www.tianqihoubao.com/aqi/hangzhou.html  \n",
    "如果查询的是历史月份，可以看到是这种格式 http://www.tianqihoubao.com/aqi/hangzhou-201702.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.tianqihoubao.com/aqi/hangzhou.html\n",
      "http://www.tianqihoubao.com/aqi/hangzhou-201805.html\n"
     ]
    }
   ],
   "source": [
    "def build_url(city_coding, year=None, month=None):\n",
    "    BASE = 'http://www.tianqihoubao.com/aqi/'\n",
    "    city_base_url = BASE + '{}.html'\n",
    "    city_data_base_url = BASE + '{}-{}{}.html'\n",
    "    \n",
    "    if year is not None and month is not None:\n",
    "        month = str(month) if month >= 10 else '0' + str(month)\n",
    "        return city_data_base_url.format(city_coding, year, month)\n",
    "    else:\n",
    "        return city_base_url.format(city_coding)\n",
    "    \n",
    "hangzhou = city_coding['杭州']\n",
    "print(build_url(hangzhou))\n",
    "print(build_url(hangzhou, 2018, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用python进行数据抓取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[HTTP请求状态](https://www.runoob.com/http/http-status-codes.html)  \n",
    "了解200 404 503"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，通过F12查看hangzhou-201805.html请求，可以看到`Content-Type: text/html; charset=gb2312` 所示使用的是GBK编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后进行HTML解析  \n",
    "参考：[Beautiful Soup 4.2.0 文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 True\n",
      "gb2312\n",
      "<title>\n",
      "\t2018年5月杭州空气质量指数查询(AQI)_5月份杭州PM2.5历史数据查询_天气后报\n",
      "</title>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "hangzhou = city_coding['杭州']\n",
    "url = build_url(hangzhou, 2018, 5)\n",
    "\n",
    "# 发送请求\n",
    "# get post\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# 查看相关信息\n",
    "# help(reponse)\n",
    "\n",
    "print(response.status_code, response.ok)\n",
    "\n",
    "# 打印返回的结果\n",
    "print(response.encoding)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "# 一些属性 \n",
    "# 网页的title\n",
    "print(soup.title)\n",
    "# 网页的文本\n",
    "# print(soup.text)\n",
    "\n",
    "# 查找属性\n",
    "data_table = soup.find_all('table')\n",
    "print(len(data_table))\n",
    "# print(data_table)\n",
    "\n",
    "# 既然只有一个table\n",
    "# 可以使用下面\n",
    "data_table = soup.table\n",
    "\n",
    "# 然后进行更加细化的数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 [('city', '日期', '质量等级', 'AQI指数', '当天AQI排名', 'PM2.5', 'PM10', 'So2', 'No2', 'Co', 'O3'), ('hangzhou', '2018-05-01', '优', '39', '35', '21', '36', '6', '28', '0.82', '52'), ('hangzhou', '2018-05-02', '良', '57', '143', '35', '57', '6', '21', '0.85', '100'), ('hangzhou', '2018-05-03', '良', '59', '124', '18', '41', '7', '31', '0.61', '104'), ('hangzhou', '2018-05-04', '良', '78', '239', '33', '66', '10', '47', '0.71', '99'), ('hangzhou', '2018-05-05', '优', '48', '73', '29', '48', '7', '43', '0.76', '60'), ('hangzhou', '2018-05-06', '优', '50', '139', '30', '50', '7', '40', '0.91', '43'), ('hangzhou', '2018-05-07', '优', '42', '65', '25', '41', '6', '30', '0.81', '51'), ('hangzhou', '2018-05-08', '良', '51', '103', '24', '43', '7', '31', '0.91', '78'), ('hangzhou', '2018-05-09', '良', '83', '258', '31', '70', '12', '44', '0.76', '102'), ('hangzhou', '2018-05-10', '良', '67', '167', '29', '62', '9', '29', '0.65', '100'), ('hangzhou', '2018-05-11', '良', '73', '263', '36', '69', '10', '47', '0.77', '86'), ('hangzhou', '2018-05-12', '良', '70', '215', '49', '84', '10', '48', '0.98', '51'), ('hangzhou', '2018-05-13', '良', '79', '213', '55', '82', '9', '31', '1.26', '88'), ('hangzhou', '2018-05-14', '良', '89', '264', '52', '82', '8', '39', '1.12', '94'), ('hangzhou', '2018-05-15', '良', '59', '154', '32', '53', '6', '29', '0.79', '83'), ('hangzhou', '2018-05-16', '良', '60', '208', '30', '53', '7', '32', '0.76', '84'), ('hangzhou', '2018-05-17', '良', '56', '140', '26', '52', '8', '36', '0.73', '72'), ('hangzhou', '2018-05-18', '良', '95', '344', '47', '77', '7', '33', '0.84', '129'), ('hangzhou', '2018-05-19', '优', '43', '39', '27', '41', '6', '23', '0.84', '67'), ('hangzhou', '2018-05-20', '优', '29', '9', '17', '26', '5', '23', '0.72', '51'), ('hangzhou', '2018-05-21', '优', '40', '66', '22', '39', '5', '34', '0.73', '36'), ('hangzhou', '2018-05-22', '优', '40', '54', '22', '36', '5', '30', '0.86', '40'), ('hangzhou', '2018-05-23', '良', '74', '195', '27', '71', '9', '26', '0.88', '122'), ('hangzhou', '2018-05-24', '轻度污染', '101', '302', '48', '112', '10', '49', '0.89', '117'), ('hangzhou', '2018-05-25', '良', '86', '267', '60', '116', '9', '54', '0.99', '79'), ('hangzhou', '2018-05-26', '良', '52', '135', '34', '55', '6', '35', '0.98', '64'), ('hangzhou', '2018-05-27', '良', '58', '124', '40', '63', '7', '39', '0.96', '34'), ('hangzhou', '2018-05-28', '良', '76', '160', '40', '67', '6', '38', '1.07', '87'), ('hangzhou', '2018-05-29', '良', '78', '196', '57', '94', '8', '55', '1.20', '53'), ('hangzhou', '2018-05-30', '轻度污染', '103', '312', '77', '128', '10', '57', '1.22', '69'), ('hangzhou', '2018-05-31', '良', '60', '155', '28', '45', '7', '27', '0.73', '94')]\n"
     ]
    }
   ],
   "source": [
    "# 查看下data_table内容\n",
    "# print(data_table)\n",
    "\n",
    "# data.contents 将对象下的元素都获取得到 返回List\n",
    "# 可以看到第一行是表头 \n",
    "# 并且隔一行有一个\\n元素\n",
    "\n",
    "name_index = 1\n",
    "content = data_table.contents[name_index:]\n",
    "\n",
    "result = []\n",
    "for index, c in enumerate(content[::2]):\n",
    "    if index == 0:\n",
    "        result.append(tuple(['city'] + c.text.split()))\n",
    "    else:\n",
    "        result.append(tuple([hangzhou] + c.text.split()))\n",
    "        \n",
    "print(len(result), result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**完整代码 for 参考**  \n",
    "[高民权_中国城市空气质量数据抓取_Github](https://github.com/fortyMiles/ChineseAirConditionCrawler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n",
      "[('city', '日期', '质量等级', 'AQI指数', '当天AQI排名', 'PM2.5', 'PM10', 'So2', 'No2', 'Co', 'O3'), ('hangzhou', '2015-10-01', '良', '53', '166', '31', '61', '9', '22', '0.75', '61'), ('hangzhou', '2015-10-02', '良', '70', '199', '32', '82', '13', '34', '0.65', '81'), ('hangzhou', '2015-10-03', '良', '70', '190', '41', '87', '14', '47', '0.80', '70'), ('hangzhou', '2015-10-04', '良', '78', '231', '56', '96', '15', '47', '0.90', '49'), ('hangzhou', '2015-10-05', '优', '43', '95', '29', '40', '10', '33', '0.74', '56'), ('hangzhou', '2015-10-06', '优', '49', '120', '33', '47', '14', '41', '0.81', '30'), ('hangzhou', '2015-10-07', '优', '39', '76', '26', '38', '18', '46', '0.78', '28'), ('hangzhou', '2015-10-08', '优', '35', '51', '23', '33', '11', '36', '0.74', '36'), ('hangzhou', '2015-10-09', '良', '54', '165', '37', '56', '10', '36', '0.74', '60'), ('hangzhou', '2015-10-10', '良', '66', '244', '45', '72', '13', '38', '0.75', '55'), ('hangzhou', '2015-10-11', '良', '78', '292', '52', '96', '22', '50', '0.82', '82'), ('hangzhou', '2015-10-12', '良', '93', '293', '69', '118', '23', '55', '0.93', '77'), ('hangzhou', '2015-10-13', '轻度污染', '107', '287', '76', '124', '23', '66', '1.01', '101'), ('hangzhou', '2015-10-14', '轻度污染', '128', '286', '97', '154', '26', '78', '1.10', '96'), ('hangzhou', '2015-10-15', '轻度污染', '141', '299', '104', '154', '20', '74', '1.03', '96'), ('hangzhou', '2015-10-16', '轻度污染', '129', '271', '93', '136', '17', '72', '0.97', '88'), ('hangzhou', '2015-10-17', '良', '78', '124', '49', '74', '16', '56', '0.60', '68'), ('hangzhou', '2015-10-18', '良', '72', '168', '46', '75', '15', '50', '0.60', '76'), ('hangzhou', '2015-10-19', '良', '77', '159', '50', '77', '14', '52', '0.65', '77'), ('hangzhou', '2015-10-20', '良', '84', '183', '56', '85', '15', '50', '0.72', '75'), ('hangzhou', '2015-10-21', '良', '60', '93', '39', '63', '13', '43', '0.64', '64'), ('hangzhou', '2015-10-22', '良', '87', '211', '63', '92', '17', '46', '0.85', '72'), ('hangzhou', '2015-10-23', '轻度污染', '102', '243', '76', '109', '16', '53', '0.97', '54'), ('hangzhou', '2015-10-24', '良', '83', '210', '60', '94', '16', '41', '0.84', '67'), ('hangzhou', '2015-10-25', '良', '64', '167', '45', '70', '15', '30', '0.71', '77'), ('hangzhou', '2015-10-26', '良', '87', '268', '63', '94', '17', '45', '0.90', '72'), ('hangzhou', '2015-10-27', '良', '54', '158', '38', '56', '8', '28', '1.02', '55'), ('hangzhou', '2015-10-28', '良', '97', '315', '71', '129', '30', '62', '0.98', '37'), ('hangzhou', '2015-10-29', '良', '84', '287', '62', '102', '19', '66', '0.96', '24'), ('hangzhou', '2015-10-30', '良', '61', '216', '41', '65', '16', '47', '0.81', '40'), ('hangzhou', '2015-10-31', '优', '45', '125', '27', '46', '18', '47', '0.61', '37')]\n",
      "test done\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_city_coding():\n",
    "    CITY_CODIN = './city_coding'\n",
    "    city_coding = {}\n",
    "    with open(CITY_CODIN, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            try:\n",
    "                city, coding = line.split('\\t')\n",
    "                city_coding[city.strip()] = coding.strip()\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "\n",
    "    return city_coding\n",
    "\n",
    "\n",
    "def build_url(city_coding, year=None, month=None):\n",
    "    BASE = 'http://www.tianqihoubao.com/aqi/'\n",
    "    city_base_url = BASE + \"{}.html\"\n",
    "    city_data_base_url = BASE + \"{}-{}{}.html\"\n",
    "\n",
    "    if year is not None and month is not None:\n",
    "        month = str(month) if month >= 10 else '0' + str(month)\n",
    "        return city_data_base_url.format(city_coding, year, month)\n",
    "    else:\n",
    "        return city_base_url.format(city_coding)\n",
    "\n",
    "\n",
    "def get_from_http(city_coding, year=None, month=None):\n",
    "    '''\n",
    "    \n",
    "    :param city_coding: city Chinese Name, e.g hangzhou \n",
    "    :param year: e.g 2016\n",
    "    :param month: e.g 10\n",
    "    :param day:  e.g 5\n",
    "    :return: {\n",
    "                'city': string,\n",
    "                'air_conditions': [air_condition]\n",
    "             }\n",
    "             \n",
    "             air_condition = (Date, AQI, Pm2.5, Pm10, No2, So2, Co, O3)\n",
    "             \n",
    "    '''\n",
    "\n",
    "    url = build_url(city_coding, year, month)\n",
    "\n",
    "    content = get_some_day_air_condition(city_coding, url)\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "def get_some_day_air_condition(city_coding, url):\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            r.encoding = 'GBK'\n",
    "            html_file = r.text\n",
    "            soup = BeautifulSoup(html_file, 'html.parser')\n",
    "\n",
    "            data_table = soup.find_all('table')\n",
    "            data_table = soup.table\n",
    "\n",
    "            return parse(city_coding, data_table)\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print('connnect error')\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse(city_coding, data):\n",
    "    #data.contents[1].text.split()\n",
    "    #data.contents[3].text.split()\n",
    "    name_index = 1\n",
    "    content = data.contents[name_index:]\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for index, c in enumerate(content[::2]):\n",
    "        if index == 0:\n",
    "            result.append(tuple(['city'] + c.text.split()))\n",
    "        else:\n",
    "            result.append(tuple([city_coding] + c.text.split()))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #get_from_http('杭州', 2015, 10, 6)\n",
    "    city_coding = get_city_coding()\n",
    "    assert city_coding['杭州'] == 'hangzhou'\n",
    "\n",
    "    hangzhou = city_coding['杭州']\n",
    "\n",
    "    print('testing')\n",
    "\n",
    "    assert build_url(hangzhou, 2016, 5) == \"http://www.tianqihoubao.com/aqi/hangzhou-201605.html\"\n",
    "    assert build_url(hangzhou, 2016) == \"http://www.tianqihoubao.com/aqi/hangzhou.html\"\n",
    "    assert build_url(hangzhou) == \"http://www.tianqihoubao.com/aqi/hangzhou.html\"\n",
    "\n",
    "    assert get_some_day_air_condition(\"hanghzhou\", \"http://www.tianqihoubao.com/aqi/hangzhou-201605.html\") is not None\n",
    "\n",
    "    data = get_some_day_air_condition(\"hangzhou\", \"http://www.tianqihoubao.com/aqi/hangzhou-201605.html\")\n",
    "    #print(data)\n",
    "\n",
    "    city_data = get_from_http('hangzhou', 2015, 10)\n",
    "    print(city_data)\n",
    "\n",
    "    print('test done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**然后使用pycharm进行项目架构介绍**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
